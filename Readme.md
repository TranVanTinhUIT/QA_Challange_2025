<h1 align="center" style="border-bottom: none; margin-bottom: 0px ">Towards Explainable Educational QA: A Chain-of-Thought and Retrieval-Augmented Approach</h1>

# Abstract

Question Answering (QA) has become a trending
task in natural language processing, particularly with the emer-
gence of advanced chatbots such as ChatGPT, Copilot, and
Claude AI that aim to address user inquiries effectively. However,
responses generated by large language models (LLMs) sometimes
lack interpretability, failing to help users understand why or
how a particular answer is derived. To address this limitation,
we propose a novel approach leveraging LLMs as natural
language understanding (NLU) engines that combine Retrieval-
Augmented Generation (RAG) with Few-Shot Learning. The
proposed system operates through a two-stage pipeline: an
initial question classification module categorizes input queries
into predefined types (e.g., Yes/No/Uncertain, ‚ÄúHow many‚Äù, and
multiple choice), followed by a reasoning engine that generates
answers accompanied by step-by-step natural language explana-
tions grounded in relevant premises. Built entirely on open-source
LLMs with fewer than 8 billion parameters, our method demon-
strates competitive performance while adhering to resource
constraints. The system achieved second place in the Explainable
AI for Educational QA Challenge [1] at TRNS-AI@IJCNN
2025, validating its effectiveness and potential for real-world
deployment in educational setting

# Folder stucture
- `/dataset`: contain dataset of the Explainable AI for Educational QA Challenge at [TRNS-AI@IJCNN 2025](https://sites.google.com/view/trns-ai/challenge/).
- `/api`: contain source code of all experiments in the paper.
  + `/api/datastore`: contain datastore using in classification module.
  + `/api/data`: contain datastore using to retrieves similar question in Numerical pipeline.
- `/out`: available all experiment results on the challenge dataset.
- `/eval`: evaluation folder.

# Environments

- The experiments run with Anaconda, Python 3.10
- Create anaconda envionment.
    ```bash
        conda env create -f environment.yml
    ```
- Activate the environment
    ```bash
        conda activate xAI-py310
    ```

# Experiments
 - The pipeline for Yes/No/Uncertain questions.
    ```bash
        python /api/yes_no_pipeline_final.py
    ```
 - The pipeline for multiple choice questions.
    ```bash
        python /api/choice_pipeline_final.py
    ```
  - The pipeline for How many/Numerical questions.
    ```bash
        python /api/hm_pipeline_final.py
    ```
  
  - Default result file located in `/out` folder.

# Evaluation
  ```bash
    python /eval/evaluation.py.py
  ```

## üìú Citation

If you find this work useful, please cite our paper:

```bibtex
@INPROCEEDINGS{Duon2512:Explainable,
AUTHOR="Van Tinh Tran and Duc Manh {Nguyen Dang} and Minh Quan Tran and Dang Khoa
{Huynh Tong} and Nguyen Khang Nguyen and Hoan Dinh and Viet Hang Duong",
TITLE="Towards Explainable Educational {QA:} A {Chain-of-Thought} and
{Retrieval-Augmented} Approach",
BOOKTITLE="2025 RIVF International Conference on Computing and Communication
Technologies (RIVF) (RIVF'25)",
ADDRESS="Ho Chi Minh city, Vietnam",
PAGES="5.98",
DAYS=17,
MONTH=dec,
YEAR=2025,
KEYWORDS="TRNS-AI(at)IJCNN25; Explainable AI; Chain-of-Thought; Retrieval Augmented
Generation; Few-short Learning"
}

```
